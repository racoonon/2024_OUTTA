{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/racoonon/2024_OUTTA/blob/main/%EC%8B%A4%EC%8A%B52_1_%EC%9E%90%EB%8F%99%EB%AF%B8%EB%B6%84_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25533d3b",
      "metadata": {
        "id": "25533d3b"
      },
      "source": [
        "# 실습 3: 자동미분(AutoDiff) 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60968f6",
      "metadata": {
        "id": "f60968f6"
      },
      "source": [
        "앞서 우리는 그래디언트 기반 학습에 대해 살펴보았다. $\\mathscr{L}$이 간단한 함수일 때는 편미분하는 것이 간단한 일이었지만, 앞으로는 손으로 편미분을 계산하기는 어려운 다양한 함수들을 $\\mathscr{L}$ 로 만나게 될 것이다. 이럴 때 필요한 것이 바로 컴퓨터의 계산 능력이다. 그래디언트 기반 학습에 대한 관심이 크게 증가하면서, 미분을 자동으로 계산해주는 자동미분 라이브러리가 여럿 개발되었다. 널리 쓰이는 라이브러리로는 [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax), [Zygote](https://github.com/FluxML/Zygote.jl) 등이 있다.\n",
        "\n",
        "이 책에서는 위의 라이브러리 중에서 쉽게 이해하고 사용할 수 있는 PyTorch 라이브러리를 사용할 것이다. 이 라이브러리는 NumPy 라이브러리와 매우 유사하게 동작하기 때문에, NumPy만 잘 알아도 쉽게 사용할 수 있다. NumPy에서 ndarray(배열)가 기본이 되는 핵심 객체인 것과 같이, PyTorch의 핵심 객체는 Tensor(텐서)라고 부른다. 이 Tensor는 ndarray와 매우 유사하게 동작이 가능하다.\n",
        "\n",
        "이 실습에서 PyTorch를 통한 자동미분에 익숙해지고 나면, 이 책 전반에 걸쳐 PyTorch를 자유자재로 사용하며 딥러닝을 배우게 될 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93acc4d",
      "metadata": {
        "id": "e93acc4d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch as tc\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d35d08",
      "metadata": {
        "id": "03d35d08"
      },
      "source": [
        "구글 코랩(Google Colab)에서는 PyTorch가 기본적으로 설치되어 있다. 따라서 별도로 설치할 필요 없이 바로 사용 가능하다. PyTorch가 제대로 설치되어 있는지 확인하려면 아래와 같은 코드를 실행해볼 수 있다.\n",
        "torch.cuda.is_available() 코드가 False의 결과가 나오면 메뉴에서\n",
        "\n",
        "런타임 > 런타임 유형 변경 > 하드웨어 가속기\n",
        "\n",
        "에서 보면 CPU가 선택되어 있을 것인데 이를 GPU로 바꿔줘야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kPxSBddWT2OT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPxSBddWT2OT",
        "outputId": "22ae7e18-fc59-4441-9ea6-4675d0898138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "# cuda는 gpu를 실행할 수 있도록 하는 일종의 플랫"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a73926ed",
      "metadata": {
        "id": "a73926ed"
      },
      "source": [
        "### Step 1. PyTorch의 여러가지 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "335815d5",
      "metadata": {
        "id": "335815d5"
      },
      "source": [
        "라이브러리를 사용할 때, 유명한 라이브러리의 경우에는 구글링을 통해 쉽게 설명된 블로그 등을 참고할 수도 있다. 하지만 정석은 라이브러리 개발자가 작성한 도큐먼트(document)를 읽는 것이다. 이 실습에서는 PyTorch를 사용한 자동미분을 배우는 것을 가장 중요한 목적으로 다루고 있으므로, 더 다양한 함수와 기능이 궁금하다면 직접 [도큐먼트](https://mygrad.readthedocs.io/en/latest/)를 읽어보길 바란다. 또한, NumPy의 기본 함수들과 일치하는 함수를 많이 가지고 있으므로, NumPy의 함수들을 찾아 PyTorch에 적용해보아도 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d06b0a0d",
      "metadata": {
        "id": "d06b0a0d"
      },
      "source": [
        "#### Tensor 생성\n",
        "Tensor는 Pytorch 라이브러리에서 사용하는 데이터를 배열 형식으로 저장하도록 한다. 다양한 방식으로 Tensor를 생성할 수 있다. 다음은 Tensor를 생성하는 여러 가지 예이다. tc.tensor 외에도 Tensor를 생성하는 다양한 함수들이 있다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42d2424d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42d2424d",
        "outputId": "2535f876-2ee9-452f-8f2c-9379fd0110a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3000)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 단일 숫자로 생성한 Tensor\n",
        "tc.tensor(2.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b71a705",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b71a705",
        "outputId": "5ba8b53a-041d-4c61-e24c-0017d1c94b67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 시퀀스(리스트, 튜플 등) 자료형으로 생성한 Tensor.\n",
        "# dtype을 지정할 수 있는 모든 함수에서\n",
        "# 32-bit floats를 저장하는 텐서를 반환하도록 지정 가능.\n",
        "tc.tensor([1.0, 2.0, 3.0], dtype=tc.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737f62f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737f62f3",
        "outputId": "70271547-7182-4f17-98aa-50e3800f0af1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# numpy.ndarray로부터 생성한 Tensor\n",
        "# np.ones 함수는 shape 인자를 튜플 형식으로 받아야함\n",
        "arr = np.ones((3, 3))\n",
        "# numpy로 받은 arr을 간단하게 tensor로 변환 가능\n",
        "tc.tensor(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970b3585",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "970b3585",
        "outputId": "aae7d3e9-3844-4788-e61f-8deab0689ebc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Tensor 생성 함수 (ones, zeros; 각각 1, 0으로 채움)\n",
        "tc.zeros((2,3,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe81f6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbe81f6c",
        "outputId": "3a1aa45f-f9de-413f-b3ef-fb463ac2db59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-5, -3, -1,  1,  3,  5,  7,  9, 11, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Tensor 생성 함수 (start 부터 stop 까지 step 만큼 띄워가며 채움)\n",
        "# 시작, 끝, 보폭 (끝 포함x)\n",
        "tc.arange(-5, 15, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae113b63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae113b63",
        "outputId": "cccb1033-5548-47cb-de70-d3167e342300"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# start = 0, step = 1이 default 값\n",
        "# 9 vs 9.\n",
        "tc.arange(9.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbdb971e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbdb971e",
        "outputId": "cd44252e-1c4d-48e2-e3ad-c7f25ad6eb5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8073, 0.1914, 0.7205, 0.7292],\n",
              "        [0.8768, 0.4514, 0.4284, 0.2526],\n",
              "        [0.1022, 0.8586, 0.6412, 0.7775]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# 0~1 사이의 값 무작위로 리턴 (확률분포는 균등분포(uniform))\n",
        "tc.rand(3, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9373be2a",
      "metadata": {
        "id": "9373be2a"
      },
      "source": [
        "<문제: 주어진 조건을 만족하는 Tensor 생성하기>\n",
        "\n",
        "구간 $[0, \\pi]$에 등간격으로 분포한 15개의 구성요소로 이루어진 shape-(15,)인 tensor를 만들어보자. (Hint: tc.linspace(), tc.pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ebd43d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ebd43d",
        "outputId": "d9c75f5d-6c4c-49ed-9e01-22ec6b9eb458",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2244, 0.4488, 0.6732, 0.8976, 1.1220, 1.3464, 1.5708, 1.7952,\n",
              "        2.0196, 2.2440, 2.4684, 2.6928, 2.9172, 3.1416])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "# 시작, 끝, 등분수 (시작과 끝 포함 => /14가 )\n",
        "tc.linspace(0, tc.pi, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71697cae",
      "metadata": {
        "id": "71697cae"
      },
      "source": [
        "#### Tensor 변형\n",
        "Tensor의 모양을 변형하는 함수들도 있다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38946f50",
      "metadata": {
        "id": "38946f50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e7c183-65a9-49bd-f2f1-00eda5402ed3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [3., 4., 5.],\n",
              "        [6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Tensor의 행과 열을 바꾸어주는 함수\n",
        "x = tc.arange(9.) #Tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])\n",
        "x.reshape(3,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a22b453",
      "metadata": {
        "id": "3a22b453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e66c1f-daca-4544-a756-cf06f3a33451"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  3,  6,  9],\n",
              "        [ 1,  4,  7, 10],\n",
              "        [ 2,  5,  8, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Tensor의 전치 행렬을 구하는 함수\n",
        "x = tc.tensor([[0,1,2], [3,4,5],[6,7,8],[9,10,11]])\n",
        "x.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a38b3441",
      "metadata": {
        "id": "a38b3441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a406212a-acc3-47ef-83fd-54bb354145ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# 슬라이싱 (자유자재로 쓸 수 있으면 좋다)\n",
        "x = tc.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n",
        "# 가장 첫 번째의 행의 세번째 원소부터\n",
        "x[0, 2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6320c0ee",
      "metadata": {
        "id": "6320c0ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9763e13-47d5-4bb4-ca9e-765ebcc1a0c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "x = tc.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n",
        "x[0, -3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6232d6c1",
      "metadata": {
        "id": "6232d6c1"
      },
      "source": [
        "#### Tensor 표준 수학 연산\n",
        "\n",
        "먼저, PyTorch에서 제공하는 표준적인 수학 함수들을 알아보자. 기본적인 산술 연산을 하는 함수를 비롯하여, (sum, mean, var, std, max, min) 등의 통계량을 구하는 함수 등이 제공된다. 또한, 삼각함수, 쌍곡함수, 지수함수, 로그함수 등의 초월함수도 제공된다. NumPy의 함수들과 동일하게, 벡터화된 함수들이다.\n",
        "\n",
        "단항 함수는 텐서에 대해 요소별로 각각 작동한다. 이항 함수는 두 텐서에 대해 대응되는 위치의 요소 간에 자연스럽게 작동한다. 두 텐서가 동일한 모양이 아니더라도 Numpy와 같은 [브로드캐스팅(Broadcasting)](https://numpy.org/doc/stable/user/basics.broadcasting.html) 규칙을 따르기 때문에, 이항 함수가 작동할 수 있는 경우가 있다.\n",
        "\n",
        "직접 코드를 실행하여 output을 확인해보자. 이를 통해 단항 연산과 이항 연산을 다루는 여러 함수에 대해 이해해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d930c8",
      "metadata": {
        "id": "b4d930c8"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor([0.0, 0.25, 0.5, 0.75, 1.0]) # 1*5\n",
        "y = tc.tensor([[0.],[1.],[2.]]) # 3*1\n",
        "z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]]) # 3*4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa53ba6b",
      "metadata": {
        "id": "aa53ba6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7ee98c-4478-4e6c-d9db-b221efbe1058"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2474, 0.4794, 0.6816, 0.8415])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# 단항 함수 중 하나인 삼각함수 sin()\n",
        "# 텐서의 모든 요소의 sin 값으로 채워진 같은 크기의 텐서\n",
        "tc.sin(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27891022",
      "metadata": {
        "id": "27891022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032acb7b-ed21-407d-dc40-6824b4ee75b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(66)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# 단항 함수 중 통계량을 구하는 함수들은 axis 인자를 가짐\n",
        "# axis가 0이면 행에 대해서만 함수를 적용하고,\n",
        "# axis가 1이면 열에 대해서만 함수를 적용\n",
        "tc.sum(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ed2ce2",
      "metadata": {
        "id": "99ed2ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e65fc8-bfd5-467e-b8ee-de09dbd1dbd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12, 15, 18, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "tc.sum(z, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628e8b1b",
      "metadata": {
        "id": "628e8b1b"
      },
      "source": [
        "z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])\n",
        "\n",
        "=>\n",
        "\n",
        "$[[0,1,2,3], \\\\\n",
        "    [4,5,6,7], \\\\\n",
        "    [8,9,10,11]]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe0294b",
      "metadata": {
        "id": "9fe0294b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d451f699-cc82-4ea4-b00b-c1f4871abad1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6, 22, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "tc.sum(z, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9686434",
      "metadata": {
        "id": "b9686434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8165c625-6d41-456d-f44c-6227764aa3be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n",
              "        [1.0000, 1.2500, 1.5000, 1.7500, 2.0000],\n",
              "        [2.0000, 2.2500, 2.5000, 2.7500, 3.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# 브로드캐스팅 예(1)\n",
        "# 크기가 작은 텐서가 크기가 큰 텐서에 맞춰서 작\n",
        "# x+y, y+z는 브로드캐스팅이 가능, x+z는 불가능\n",
        "x+y # 3*5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0e5310",
      "metadata": {
        "id": "6c0e5310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329f4fa7-bc02-4c49-ef50-0c1db7c19e3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 5.,  6.,  7.,  8.],\n",
              "        [10., 11., 12., 13.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "y+z # 3*4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef7e7090",
      "metadata": {
        "id": "ef7e7090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "0b8b7625-d5f4-472d-9cb5-393c824c26a3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-0e52b3dd32a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "x+z # Error 발생"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942ebf93",
      "metadata": {
        "id": "942ebf93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b219abc-f986-4edc-b18f-39a9547f7097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n",
              "        [0.0000, 0.5000, 1.0000, 1.5000, 2.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# 브로드캐스팅 예(2)\n",
        "# x*y, y*z는 브로드캐스팅이 가능, x*z는 불가능\n",
        "x*y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b61b7f",
      "metadata": {
        "id": "45b61b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf38d6fa-5925-4fa5-be11-11964c3e4662"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  0.,  0.,  0.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [16., 18., 20., 22.]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "y*z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b613e37",
      "metadata": {
        "id": "6b613e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "27fc7963-2fc9-4469-c9c0-0c2be8bea947"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-babf0bcfe656>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "x*z # Error 발생"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad45aec1",
      "metadata": {
        "id": "ad45aec1"
      },
      "source": [
        "<문제: Pytorch의 기본 수학 연산>\n",
        "\n",
        "아래와 같이 정의된 텐서 x에 대해 여러 가지 수학 연산을 적용하여 여러 가지 텐서를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98929d0",
      "metadata": {
        "id": "a98929d0"
      },
      "outputs": [],
      "source": [
        "x = tc.Tensor([[ 0.,  1.,  2.,  3.],\n",
        "...                [ 4.,  5.,  6.,  7.],\n",
        "...                [ 8.,  9., 10., 11.],\n",
        "...                [12., 13., 14., 15.]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1번 문제"
      ],
      "metadata": {
        "id": "prqrJypdiwJ2"
      },
      "id": "prqrJypdiwJ2"
    },
    {
      "cell_type": "markdown",
      "id": "6e03887e",
      "metadata": {
        "id": "6e03887e"
      },
      "source": [
        "1. x의 3행의 첫번째, 세번째 원소에 대한 자연로그 값으로 채워진 shape-(2,)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b89e057",
      "metadata": {
        "id": "7b89e057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3b3cef-3b9b-443a-f696-0e367243ebdd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0794, 2.3026])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "tc.log(x[2,0::2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1e928f",
      "metadata": {
        "id": "3d1e928f"
      },
      "source": [
        "## 1번 문제 정답"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc.log(x[2,0::2])"
      ],
      "metadata": {
        "id": "2wSGga_FiWIq"
      },
      "id": "2wSGga_FiWIq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 문제 출력 결과 : tensor([2.0794, 2.3026])"
      ],
      "metadata": {
        "id": "F7fzgO9kikUX"
      },
      "id": "F7fzgO9kikUX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2번 문제"
      ],
      "metadata": {
        "id": "6M3xaJomisFT"
      },
      "id": "6M3xaJomisFT"
    },
    {
      "cell_type": "markdown",
      "id": "65c19bdd",
      "metadata": {
        "id": "65c19bdd"
      },
      "source": [
        "2. x를 가로, 세로로 4등분한 각 귀퉁이(왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래)의 4개 원소를 더하여 shape-(2,2)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0076def",
      "metadata": {
        "id": "b0076def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094f323e-7acc-48a9-8113-74fff5b84173"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20., 24.],\n",
              "        [36., 40.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "# x를 2*2 sub tensor로 나눈 후 합\n",
        "x[:2,:2] + x[:2,2:] + x[2:,:2] + x[2:,2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2번 문제 정답"
      ],
      "metadata": {
        "id": "AyY6znLKidQj"
      },
      "id": "AyY6znLKidQj"
    },
    {
      "cell_type": "code",
      "source": [
        "x[:2,:2] + x[:2,2:] + x[2:,:2] + x[2:,2:]"
      ],
      "metadata": {
        "id": "a3JavlrAi3Nn"
      },
      "id": "a3JavlrAi3Nn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2번 문제 출력 결과 :\n",
        "\n",
        "tensor([[20., 24.],\\\n",
        "        [36., 40.]])"
      ],
      "metadata": {
        "id": "2ZYKqDfmjKFu"
      },
      "id": "2ZYKqDfmjKFu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3번 문제"
      ],
      "metadata": {
        "id": "t8AcEm9Ni-9i"
      },
      "id": "t8AcEm9Ni-9i"
    },
    {
      "cell_type": "markdown",
      "id": "d18ec6e0",
      "metadata": {
        "id": "d18ec6e0"
      },
      "source": [
        "  3. x의 각 열의 평균을 구하여 shape-(4,)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ff6a6bc",
      "metadata": {
        "id": "5ff6a6bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702c5782-4ac5-428c-974f-155a165c9375"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6., 7., 8., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "# 행을 따라 평균 계산\n",
        "tc.mean(x, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3번 문제 정답"
      ],
      "metadata": {
        "id": "Mf_Q1BkEjoCf"
      },
      "id": "Mf_Q1BkEjoCf"
    },
    {
      "cell_type": "code",
      "source": [
        "x.mean(axis=0)"
      ],
      "metadata": {
        "id": "-pmoGU-0jnk5"
      },
      "id": "-pmoGU-0jnk5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번 문제 출력 결과 : tensor([6., 7., 8., 9.])"
      ],
      "metadata": {
        "id": "Pn-E0xyKjobv"
      },
      "id": "Pn-E0xyKjobv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4번 문제"
      ],
      "metadata": {
        "id": "W7y-HGgwjzr7"
      },
      "id": "W7y-HGgwjzr7"
    },
    {
      "cell_type": "markdown",
      "id": "d29b6965",
      "metadata": {
        "id": "d29b6965"
      },
      "source": [
        "4. x의 각 행을 벡터로보고, 각 벡터가 크기가 1이 되도록 정규화하여 shape-(4,4)인 Tensor로 업데이트해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57234e34",
      "metadata": {
        "id": "57234e34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dadd246-f735-424c-c422-75423812e8e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.2673, 0.5345, 0.8018],\n",
              "        [0.3563, 0.4454, 0.5345, 0.6236],\n",
              "        [0.4182, 0.4704, 0.5227, 0.5750],\n",
              "        [0.4429, 0.4798, 0.5167, 0.5537]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "norms = x.norm(p=2, dim=1, keepdim=True)\n",
        "x /= norms\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d038eb54",
      "metadata": {
        "id": "d038eb54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75abc7bc-73d5-43b4-ef6c-59508c32e65f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# 정규화가 잘 되었는지 확인하기\n",
        "tc.sum(x**2, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4번 문제 정답"
      ],
      "metadata": {
        "id": "-zPuP1PPj_yj"
      },
      "id": "-zPuP1PPj_yj"
    },
    {
      "cell_type": "code",
      "source": [
        "x /= tc.sqrt(tc.sum(x**2,axis=1,keepdims = True))\n",
        "x"
      ],
      "metadata": {
        "id": "hZ_679jyj3rQ"
      },
      "id": "hZ_679jyj3rQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4번 문제 출력 결과 : \\\\\n",
        "\n",
        "tensor([[0.0000, 0.2673, 0.5345, 0.8018], \\\n",
        "        [0.3563, 0.4454, 0.5345, 0.6236], \\\n",
        "        [0.4182, 0.4704, 0.5227, 0.5750], \\\n",
        "        [0.4429, 0.4798, 0.5167, 0.5537]])"
      ],
      "metadata": {
        "id": "dVP8WS0PkDKT"
      },
      "id": "dVP8WS0PkDKT"
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화가 잘 되었는지 확인하기 정답\n",
        "(x**2).sum(axis=1)"
      ],
      "metadata": {
        "id": "J9xPBjRsj3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bdc94e-083a-4936-aff2-dd31744c538a"
      },
      "id": "J9xPBjRsj3ff",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   "
      ],
      "metadata": {
        "id": "n8GyohNmkccZ"
      },
      "id": "n8GyohNmkccZ"
    },
    {
      "cell_type": "markdown",
      "id": "ca7b8e69",
      "metadata": {
        "id": "ca7b8e69"
      },
      "source": [
        "#### 선형대수 연산 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ce788e",
      "metadata": {
        "id": "47ce788e"
      },
      "source": [
        "PyTorch에는 선형대수 연산을 쉽게 계산하도록 도와주는 함수들도 있다. matmul()은 행렬곱을 계산해주는 함수이다. 이를 이용하여 벡터의 점곱(스칼라곱)을 계산할 수도 있다. einsum()은 아인슈타인 표기법(Einstein notation 또는 Einstein summation convention)을 계산하는 함수이다. 이는 다소 복잡한 함수이지만, 다양한 사용자 지정 가능한 선형 대수 연산을 수행할 수 있다. PyTorch가 자동미분을 수행할 때 이 연산들을 통해 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "171b9c09",
      "metadata": {
        "id": "171b9c09"
      },
      "source": [
        "먼저 이항 연산 함수인 matmul()연산은 행렬곱을 기본으로 하는 함수이므로 2차원 텐서 간의 연산이 가장 자연스럽게 정의된다. 1차원 텐서 간의 matmul()을 명령하면 1차원 텐서를 1xn 크기의 2차원 텐서로 생각하여 연산을 진행한다. 그리고 n차원(3차원 이상)의 텐서 간의 matmul()은 n-2차원의 텐서의 구성요소가 2차원 텐서(행렬)인 것으로 생각하여 연산을 진행한다. 즉, 행렬이 여러개 모여있는 것으로 생각하고 행렬곱을 진행하는 것이다. matmul()연산 또한 NumPy의 브로드캐스팅 규칙을 따르는 함수이기 때문에 3차원 이상의 텐서에 대해서는 브로드캐스팅에도 유의해야 한다.\n",
        "\n",
        "matmul()을 사용할 때는 tc.matmul(x,y)로 사용할 수 있지만, x @ y 와 같이 연산자 @를 이용하여도 같은 연산을 할 수 있도록 정의되어 있다. 아래의 사용 예시를 따라가면 matmul() 함수의 사용법을 이해할 수 있을 것이다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d89dcb",
      "metadata": {
        "id": "c0d89dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9c9357-4145-487f-a449-0ca5235281b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-11.)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n",
        "x = tc.tensor([1.0, 2.0])\n",
        "y = tc.tensor([-3.0, -4.0])\n",
        "tc.matmul(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n",
        "x = tc.tensor([1.0, 2.0])\n",
        "y = tc.tensor([-3.0, -4.0])\n",
        "x @ y"
      ],
      "metadata": {
        "id": "oKmJhLeklBTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4c58b8-133b-4271-9126-ddb803ca305b"
      },
      "id": "oKmJhLeklBTI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-11.)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594d0ad6",
      "metadata": {
        "id": "594d0ad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3bb29f4-b031-4c1b-c39c-45ea0cd4057b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  1,  5],\n",
              "        [ 2,  2,  6],\n",
              "        [10,  4, 16],\n",
              "        [20, 11, 39]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# 2차원 텐서의 matmul 연산은 그냥 행렬곱과 같음\n",
        "a = tc.tensor([[1, 0], [0, 1], [2, 1], [3, 4]]) # 4*2\n",
        "b = tc.tensor([[4, 1, 5], [2, 2, 6]]) # 2*3\n",
        "tc.matmul(a, b) # a @ b ; 4*3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "375463a3",
      "metadata": {
        "id": "375463a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be797fec-1046-41a6-b976-d150ef731b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5]],\n",
            "\n",
            "        [[ 2,  3,  4],\n",
            "         [ 5,  6,  7]],\n",
            "\n",
            "        [[ 4,  5,  6],\n",
            "         [ 7,  8,  9]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11]]])\n",
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5],\n",
            "         [ 6,  7,  8]],\n",
            "\n",
            "        [[ 2,  3,  4],\n",
            "         [ 5,  6,  7],\n",
            "         [ 8,  9, 10]],\n",
            "\n",
            "        [[ 4,  5,  6],\n",
            "         [ 7,  8,  9],\n",
            "         [10, 11, 12]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11],\n",
            "         [12, 13, 14]]])\n",
            "tensor([[[ 15,  18,  21],\n",
            "         [ 42,  54,  66]],\n",
            "\n",
            "        [[ 51,  60,  69],\n",
            "         [ 96, 114, 132]],\n",
            "\n",
            "        [[111, 126, 141],\n",
            "         [174, 198, 222]],\n",
            "\n",
            "        [[195, 216, 237],\n",
            "         [276, 306, 336]]])\n"
          ]
        }
      ],
      "source": [
        "# A는 크기가 (4, 2, 3)인 3차원 텐서\n",
        "# 2*3=6이 stop\n",
        "A1 = tc.arange(2*3).reshape((2,3))\n",
        "A = tc.stack([A1, A1+2, A1+4, A1+6])\n",
        "\n",
        "# B는 크기가 (4, 3, 3)인 3차원 텐서\n",
        "B1 = tc.arange(3*3).reshape((3,3))\n",
        "B = tc.stack([B1, B1+2, B1+4, B1+6])\n",
        "\n",
        "# matmul 연산을 제대로 이해했는지 확인하기 위해\n",
        "# 손으로도 직접 계산해보고, 결과가 동일한지 확인해보기\n",
        "print(A)\n",
        "print(B)\n",
        "print(tc.matmul(A, B))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6479f8f0",
      "metadata": {
        "id": "6479f8f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740bf10d-82ed-452b-c2e3-e80ed5cbc6ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2, 3])\n",
            "tensor([[[ 15,  18,  21],\n",
            "         [ 42,  54,  66]],\n",
            "\n",
            "        [[ 51,  60,  69],\n",
            "         [ 96, 114, 132]],\n",
            "\n",
            "        [[111, 126, 141],\n",
            "         [174, 198, 222]],\n",
            "\n",
            "        [[195, 216, 237],\n",
            "         [276, 306, 336]]])\n"
          ]
        }
      ],
      "source": [
        "C = tc.matmul(A, B)\n",
        "print(C.shape) # .shape 많이 쓰임; 어떤 tensor 모양인지\n",
        "print(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4b01755",
      "metadata": {
        "id": "e4b01755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bfedae5-aa2e-4bb9-ae54-f3a0e89881c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.8837, 0.8812],\n",
              "         [1.1328, 0.5588],\n",
              "         [0.5951, 0.2861]],\n",
              "\n",
              "        [[0.8660, 0.7786],\n",
              "         [0.6128, 0.4270],\n",
              "         [1.0933, 0.7368]],\n",
              "\n",
              "        [[0.9714, 1.0108],\n",
              "         [1.6162, 1.2815],\n",
              "         [1.3230, 0.9404]],\n",
              "\n",
              "        [[0.5928, 0.8220],\n",
              "         [1.3836, 0.8073],\n",
              "         [1.3041, 0.8912]],\n",
              "\n",
              "        [[1.5261, 0.7164],\n",
              "         [1.0842, 0.7850],\n",
              "         [1.0134, 0.5427]]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# 브로드캐스팅 예 (y를 5개로 브로드캐스팅하여 x와 연산)\n",
        "x = tc.rand(5,3,4)\n",
        "y = tc.rand(4,2)\n",
        "tc.matmul(x,y) # x @ y ; 5*3*2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb78257",
      "metadata": {
        "id": "7bb78257"
      },
      "source": [
        "NumPy에서는 행렬곱 연산을 하는 함수가 두 개 있다. 바로 dot연산과 matmul 연산이다.두 함수는 2차원 배열 두개의 곱에 대해 동일한 행렬곱을 결과로 도출한다. 그러나 3차원 이상에서는 서로 다르게 동작한다. 이 두 함수의 차이가 궁금하다면 직접 검색하여 공부해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3a1d7c",
      "metadata": {
        "id": "1a3a1d7c"
      },
      "source": [
        "다음으로 einsum()함수는 행렬 연산에 관한 다양한 함수들을 다 알지 못하더라도, 이 함수 하나만을 가지고 다양한 행렬 연산을 사용자가 직접 지정해줄 수 있는 함수이다. 이 함수의 원리는 아인슈타인 표기법을 따르는데, 아인슈타인 표기법에 대해 스스로 검색하여 공부해보면 Numpy와 PyTorch에서 einsum()함수를 사용하는 예시들을 쉽게 이해할 수 있을 것이다.\n",
        "\n",
        "아래의 예시들을 직접 실행해보며 einsum()함수의 유용함을 느껴보자, einsum()함수에 대해 완벽히 이해하지 못했더라도 괜찮다. 다만 앞으로 einsum()함수의 새로운 사용 예시를 보게 되더라도 낯설고 어렵게 느끼지 말고, 익숙하게 느끼길 바란다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beabda70",
      "metadata": {
        "id": "beabda70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af838a0-3800-424a-f9c3-576386780c42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8,  9],\n",
              "         [10, 11, 12, 13, 14],\n",
              "         [15, 16, 17, 18, 19],\n",
              "         [20, 21, 22, 23, 24]]),\n",
              " tensor([[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8],\n",
              "         [ 9, 10, 11],\n",
              "         [12, 13, 14]]),\n",
              " tensor([[  0,  -1,  -2],\n",
              "         [ -3,  -4,  -5],\n",
              "         [ -6,  -7,  -8],\n",
              "         [ -9, -10, -11],\n",
              "         [-12, -13, -14]]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "a = tc.arange(25).reshape(5,5)\n",
        "b = tc.arange(15).reshape(5,3)\n",
        "c = -tc.arange(15).reshape(5,3)\n",
        "a, b, c"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i는 행, j는 열을 뜻함\n"
      ],
      "metadata": {
        "id": "SO5CvLLnsh_n"
      },
      "id": "SO5CvLLnsh_n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6166eb9",
      "metadata": {
        "id": "c6166eb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbac8d3d-563b-4c25-9c94-247d832d22f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(60)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# a의 대각합\n",
        "tc.einsum(\"ii\", a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e81572d",
      "metadata": {
        "id": "7e81572d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8809fb23-a80b-4a16-8136-9bc012588662"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  6, 12, 18, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# a의 대각원소\n",
        "tc.einsum('ii->i',a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc252f98",
      "metadata": {
        "id": "bc252f98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "562a9f2e-624f-4d3b-fed1-7f99c7da6bc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  3,  6,  9, 12],\n",
              "        [ 1,  4,  7, 10, 13],\n",
              "        [ 2,  5,  8, 11, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# b의 전치행렬\n",
        "tc.einsum('ji',b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d586edc",
      "metadata": {
        "id": "6d586edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb210d2-fb72-450b-efa9-b222f93417f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 90, 100, 110],\n",
              "         [240, 275, 310],\n",
              "         [390, 450, 510],\n",
              "         [540, 625, 710],\n",
              "         [690, 800, 910]]),\n",
              " tensor([[ 90, 100, 110],\n",
              "         [240, 275, 310],\n",
              "         [390, 450, 510],\n",
              "         [540, 625, 710],\n",
              "         [690, 800, 910]]))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# a와 b의 행렬곱 계산 (matmul과 결과가 동일함을 확인해보기)\n",
        "tc.einsum('ij,jk->ik',a,b), tc.matmul(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976de1a0",
      "metadata": {
        "id": "976de1a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c97a7f3-47ea-44c6-cbf3-61a463e3f834"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  -5,  -50, -149, -302, -509])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# 같은 모양의 텐서 b,c의 각 행끼리의 점곱을 계산\n",
        "tc.einsum(\"ij,ij->i\",b,c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50bdd8c5",
      "metadata": {
        "id": "50bdd8c5"
      },
      "source": [
        "#### 자동미분과 딥러닝을 위한 특수 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6676ae0f",
      "metadata": {
        "id": "6676ae0f"
      },
      "source": [
        "PyTorch는 NumPy와 유사한 함수들 외에도 PyTorch만의 딥러닝을 위한 특수 함수들을 제공합니다. torch.nn 모듈에서는 딥러닝을 진행할 신경망을 구현하는 데 필요한 손실 함수(loss function), 활성 함수(activation function), 초기화 함수(initializer)의 대표적인 예시들을 제공합니다. 이러한 함수들에 대해서는 이번 실습에서는 다루지 않을 것이지만, 바로 다음 실습부터 꾸준히 여러 함수들이 등장할 예정입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a37a44",
      "metadata": {
        "id": "e1a37a44"
      },
      "source": [
        "### Step 2 자동미분 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d850545d",
      "metadata": {
        "id": "d850545d"
      },
      "source": [
        "이제 PyTorch 라이브러리의 핵심 기능인 자동미분에 대해 알아보자. PyTorch를 비롯한 대부분의 자동미분 라이브러리는 함수의 도함수(편도함수)를 직접 구하지 않는다. 그 대신 주어진 점(입력값)에서의 미분계수(편미분계수) 값을 구한다. 즉, 자동미분 라이브러리는 지정해준 점에서의 함수의 순간 기울기를 구하는 기능만을 갖고 있으며, 우리는 이를 이용하여 미분가능한 모든 함수의 모든 지점에서의 기울기를 구할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56abc047",
      "metadata": {
        "id": "56abc047"
      },
      "source": [
        "#### 텐서 객체의 '.backward()' 메서드"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e4dd1f7",
      "metadata": {
        "id": "0e4dd1f7"
      },
      "source": [
        "PyTorch에서 자동미분을 호출하기 위해 필요한 유일한 방법은 Tensor.backward()이다. 다른 텐서로부터 계산한 텐서 F에 대해 F.backward()를 호출하면, PyTorch는 F가 의존하는 모든 텐서에 대해 F의 편미분계수를 계산하도록 지시한다. 이 편미분계수들은 각각의 텐서들의 .grad 속성에 Tensor로 저장된다. 이때 몇 가지 주의사항이 있다.\n",
        "\n",
        "1. requires_grad=True:\n",
        "자동 미분을 추적하려면 텐서를 생성할 때 requires_grad=True로 설정해야 한다.\n",
        "\n",
        "2. backward() 호출:\n",
        "Tensor.backward()를 호출하면 해당 텐서로부터 계산된 모든 텐서에 대해 그래디언트(기울기)를 계산합니다. backward()는 스칼라 값에 대해서만 호출할 수 있습니다. 만약 텐서가 스칼라가 아니라면, 적절한 축소 연산을 통해 스칼라로 변환한 후 backward()를 호출해야 한다 (예: sum())."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee0edf3a",
      "metadata": {
        "id": "ee0edf3a"
      },
      "source": [
        "예를 들어 아래와 같이 x, y, z 텐서가 있고, x와 y의 함수로 정의된 f 텐서가 있는 상황에서의 편미분을 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8909fc52",
      "metadata": {
        "id": "8909fc52"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "y = tc.tensor(3.0, requires_grad=True)\n",
        "z = tc.tensor(4.0, requires_grad=True)\n",
        "f = x * y # tc.multiply(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b04f19",
      "metadata": {
        "id": "d9b04f19"
      },
      "source": [
        "이 때, f.backward()를 호출하면 PyTorch가 f의 모든 편미분계수를 계산하도록 지시한다. 이는 역전파(backpropagation)라고 하는 컴퓨터가 빠르게 편미분계수를 계산할 수 있는 알고리즘을 사용하여 수행된다. 역전파 알고리즘은 딥러닝의 발전에서 빠질 수 없는 핵심적인 알고리즘이라 할 수 있는 것으로, 연쇄법칙(chain rule)에 기반한 알고리즘이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff5c10e",
      "metadata": {
        "id": "eff5c10e"
      },
      "outputs": [],
      "source": [
        "# pytorch가 f의 모든 편미분 계수를 계산하도록\n",
        "f.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a891efdb",
      "metadata": {
        "id": "a891efdb"
      },
      "source": [
        "x와 y의 .grad() 속성을 살펴보면 $\\frac{d F}{d x}$와 $\\frac{d F}{dy}$의 값을 얻을 수 있다. .grad()는 텐서로 구해진다. z는 f가 의존하는 변수 텐서가 아니므로 .grad() 속성에 값이 없다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "692b2f01",
      "metadata": {
        "id": "692b2f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5bbad7-049b-4735-ea97-8866612bf5d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "208b6de2",
      "metadata": {
        "id": "208b6de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81826007-597a-49b4-e15a-dd32db954b4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "y.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5d2ed2",
      "metadata": {
        "id": "7d5d2ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8701c5c8-7ef4-4d87-f3b3-df3579f97ba8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "z.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7cd692",
      "metadata": {
        "id": "ab7cd692"
      },
      "source": [
        "이번에는 x, y, 그리고 x와 y로부터 구해지는 f까지 세 텐서에 의존하는 텐서 F의 모든 편미분계수를 계산해보자. 즉, F(f(x, y), x, y)인 경우를 살펴볼 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cebffb7",
      "metadata": {
        "id": "2cebffb7"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "y = tc.tensor(3.0, requires_grad=True)\n",
        "f = x * y\n",
        "f.retain_grad()\n",
        "F = f + x - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a90c30f",
      "metadata": {
        "id": "1a90c30f"
      },
      "outputs": [],
      "source": [
        "F.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cb35f93",
      "metadata": {
        "id": "5cb35f93"
      },
      "source": [
        "f의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial f}$의 값을 얻을 수 있다.\n",
        "y의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial y} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial y}$의 값을 얻을 수 있다.\n",
        "\n",
        "마지막으로 x의 경우, t = x에 대해 F = f + t - 2로 쓸 수 있다. 이렇게 생각하고 x의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial x} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial x} + \\frac{\\partial F}{\\partial t}\\frac{\\partial t}{\\partial x}$의 값을 얻을 수 있다.\n",
        "\n",
        "주의사항으로 PyTorch에서 특정 텐서의 그래디언트를 계산하기 위해서는 그 텐서에 대해 직접적으로 requires_grad=True를 설정하고, 필요하다면 중간 텐서에 대해서도 retain_grad() 메소드를 호출해야 한다. retain_grad()는 중간 텐서의 그래디언트를 저장하도록 한다. f.retain_grad() 코드가 없다면 어떻게 실행되는지 확인해보는 것도 좋을 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a4384e",
      "metadata": {
        "id": "17a4384e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0135d5c1-bbf3-4fb7-959f-9f848af5f834"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "f.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3da1420",
      "metadata": {
        "id": "c3da1420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c76dd1-640b-4b40-a65b-2d96b23ad654"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "y.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f394a3",
      "metadata": {
        "id": "f0f394a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276a136d-5acf-4763-bce5-9e5eca490ed0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06825fb4",
      "metadata": {
        "id": "06825fb4"
      },
      "source": [
        "f와 F가 의존하는 모든 변수들이 PyTorch의 텐서로 저장되어 있었고, f와 F를 이루는 모든 수학적 연산이 PyTorch에서 제공하는 함수였기 때문에 PyTorch를 통해 F의 모든 편미분계수를 구할 수 있었다. 이렇게 구한 편미분계수들로부터 함수의 그래디언트를 이용하는 경사하강법을 쉽게 수행할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05aac9d3",
      "metadata": {
        "id": "05aac9d3"
      },
      "source": [
        "# 문제: 텐서 객체의 backward() 메서드 사용\n",
        "\n",
        "여러가지 수식으로 정의된 x에 대한 함수 F에 대해, x=2.5에서 $\\frac{d F}{d x}\\big|_{x=2.5}$를 구해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1번 문제"
      ],
      "metadata": {
        "id": "MAGBsn7xGd1k"
      },
      "id": "MAGBsn7xGd1k"
    },
    {
      "cell_type": "markdown",
      "id": "f35f6a9d",
      "metadata": {
        "id": "f35f6a9d"
      },
      "source": [
        "1. $F(x)=x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad9f204",
      "metadata": {
        "id": "1ad9f204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c39d4b8-db79-4306-845d-e542c3ff3f29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = x**2\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1번 문제 정답"
      ],
      "metadata": {
        "id": "xfCuA6MxGEHh"
      },
      "id": "xfCuA6MxGEHh"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = x**2\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "hA-iU8diGMxo"
      },
      "id": "hA-iU8diGMxo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 문제 출력 결과 : tensor(5.)"
      ],
      "metadata": {
        "id": "YIOuj1FMGPMw"
      },
      "id": "YIOuj1FMGPMw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2번 문제"
      ],
      "metadata": {
        "id": "ekFW_3OnGSdU"
      },
      "id": "ekFW_3OnGSdU"
    },
    {
      "cell_type": "markdown",
      "id": "7a5cd97f",
      "metadata": {
        "id": "7a5cd97f"
      },
      "source": [
        "2. $F(x)=\\cos{\\sqrt{x}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62fd0dd",
      "metadata": {
        "id": "f62fd0dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc96d0b-b7e5-4b34-ab91-b8706ce191eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.3162)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.cos(tc.sqrt(x))\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2번 문제 정답"
      ],
      "metadata": {
        "id": "G1rUUHZFGi-3"
      },
      "id": "G1rUUHZFGi-3"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.cos(tc.sqrt(x))\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "4V1iRDD3GijE"
      },
      "id": "4V1iRDD3GijE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2번 문제 출력 결과 : tensor(-0.3162)"
      ],
      "metadata": {
        "id": "dIrwUZzyGibE"
      },
      "id": "dIrwUZzyGibE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3번 문제"
      ],
      "metadata": {
        "id": "aBe8aYzXGr3G"
      },
      "id": "aBe8aYzXGr3G"
    },
    {
      "cell_type": "markdown",
      "id": "f994e9f9",
      "metadata": {
        "id": "f994e9f9"
      },
      "source": [
        "3. $F(x)=2+3x-5x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aba45f7",
      "metadata": {
        "id": "9aba45f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59706ae8-eb3c-4879-9c8f-2d5110019623"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-22.)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = 2 + 3*x - 5*x**2\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3번 문제 정답"
      ],
      "metadata": {
        "id": "b-l8ieGVGv3M"
      },
      "id": "b-l8ieGVGv3M"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = 2+3*x-5*x**2\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "mEgwk9LhGuT6"
      },
      "id": "mEgwk9LhGuT6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번 문제 출력 결과 : tensor(-22.)"
      ],
      "metadata": {
        "id": "gOabd2fPGul7"
      },
      "id": "gOabd2fPGul7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4번 문제"
      ],
      "metadata": {
        "id": "0oTiFRY5G2tE"
      },
      "id": "0oTiFRY5G2tE"
    },
    {
      "cell_type": "markdown",
      "id": "aa6ca763",
      "metadata": {
        "id": "aa6ca763"
      },
      "source": [
        "4. $F(x)=e^{lnx}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d028375e",
      "metadata": {
        "id": "d028375e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43250b67-95fb-48e5-ee1d-3de6516a89be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.exp(tc.log(x))\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4번 문제 정답"
      ],
      "metadata": {
        "id": "rbGPZ_ydG53A"
      },
      "id": "rbGPZ_ydG53A"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.exp(tc.log(x))\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "dLQKI_84G5Sa"
      },
      "id": "dLQKI_84G5Sa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4번 문제 출력 결과 : tensor(1.)"
      ],
      "metadata": {
        "id": "G49bEx7jG5e4"
      },
      "id": "G49bEx7jG5e4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5번 문제"
      ],
      "metadata": {
        "id": "9UFMZxcHHEX5"
      },
      "id": "9UFMZxcHHEX5"
    },
    {
      "cell_type": "markdown",
      "id": "979502fa",
      "metadata": {
        "id": "979502fa"
      },
      "source": [
        "5. $F(x)=(2xf(x))^2-f(x), f(x)=x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e333cb51",
      "metadata": {
        "id": "e333cb51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf23d639-b25c-4540-eb6f-e1c1446cbed8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2338.7500)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "f = x**2\n",
        "F = (2*x*f)**2-f\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5번 문제 정답"
      ],
      "metadata": {
        "id": "U0_bPo_AHGKV"
      },
      "id": "U0_bPo_AHGKV"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "f = x**2\n",
        "F = (2*x*f)**2-f\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "PmQlhnDvHGbA"
      },
      "id": "PmQlhnDvHGbA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5번 문제 출력 결과 : tensor(2338.7500)"
      ],
      "metadata": {
        "id": "mfseKPKcHGwV"
      },
      "id": "mfseKPKcHGwV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -"
      ],
      "metadata": {
        "id": "1wT96P_lHMrw"
      },
      "id": "1wT96P_lHMrw"
    },
    {
      "cell_type": "markdown",
      "id": "72ea07a0",
      "metadata": {
        "id": "72ea07a0"
      },
      "source": [
        "#### .grad 속성의 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e8e4d75",
      "metadata": {
        "id": "0e8e4d75"
      },
      "source": [
        "경사하강법을 수행할 때, 텐서와 관련된 편미분계수를 반복적으로 구해야 한다. 따라서, 경사하강을 반복할 때마다 사이사이에 편미분계수를 폐기해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fce6da3",
      "metadata": {
        "id": "6fce6da3"
      },
      "source": [
        "backward()연산을 진행한 함수가 의존하는 텐서들 중 하나의 .grad 속성을 초기화하는 방법은 다음과 같이 두가지가 있다. 아래와 같은 상황을 생각해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b77985",
      "metadata": {
        "id": "45b77985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba2ee54-fffb-4c20-ccd8-c8da7a47f203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "f = x**2\n",
        "f.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0e92ca",
      "metadata": {
        "id": "9b0e92ca"
      },
      "source": [
        "그래디언트를 초기화하지 않으면, 추가 연산 후 backward()를 호출해도 이전 값에 누적되지 않고 덮어쓴다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a13d5b",
      "metadata": {
        "id": "c7a13d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1f3579-c354-4461-fde1-c92e6e4ad430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "g = x**2\n",
        "g.backward()\n",
        "# f에서의 grad에 g에서의 grad까지 중첩\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6477d424",
      "metadata": {
        "id": "6477d424"
      },
      "source": [
        "Tensor.grad를 호출하여 해당 텐서의 .grad 속성을 직접적으로 None으로 재설정할 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71cbc888",
      "metadata": {
        "id": "71cbc888"
      },
      "outputs": [],
      "source": [
        "x.grad = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3fb5eb",
      "metadata": {
        "id": "0d3fb5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3935b6f-fcb4-4195-9dce-9c70f2d536d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "x.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6de8423c",
      "metadata": {
        "id": "6de8423c"
      },
      "source": [
        "#### PyTorch와 Numpy의 관계"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4133bbb6",
      "metadata": {
        "id": "4133bbb6"
      },
      "source": [
        "우리는 앞의 내용에서 PyTorch에서 NumPy의 다양한 수학함수들을 동일하게 정의해두었다는 것을 충분히 확인했다.\n",
        "\n",
        "PyTorch의 텐서 객체는 NumPy 배열과 비교했을 때 별로 새롭지 않다. 텐서 객체는 Numpy 배열에 대한 정보를 기본으로 가지고 있으며, 단지 배열이 관련된 수학적 연산들을 추적하는 추가 역할을 할 뿐이다. 수학적 연산에 대한 추적은 자동미분을 위해 추가된 역할이라고 볼 수 있다.\n",
        "\n",
        "이러한 관계성에 의해 우리는 텐서를 한꺼풀 벗겨내어 NumPy 배열을 얻을 수 있다. 다음의 텐서 x에 대해 NumPy 배열로 만드는 세 가지 방법을 확인해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7I3HEHz_gIFV",
      "metadata": {
        "id": "7I3HEHz_gIFV"
      },
      "source": [
        "먼저, 기본 텐서의 경우 numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55472dc7",
      "metadata": {
        "id": "55472dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fd7ac76-9d12-4164-a564-df09ac50f67b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "x = tc.tensor([0.0,1.0,2.0,3.0])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef96a8b",
      "metadata": {
        "id": "1ef96a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83cebe99-0a45-49fc-9e13-a2fce37db0bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "x.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e22945e",
      "metadata": {
        "id": "9e22945e"
      },
      "source": [
        "두번째로, grad 정보가 포함된 경우 detach().numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac022abd",
      "metadata": {
        "id": "ac022abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52f4a81-5ad7-49dd-ddd1-7e9f56ee8ec4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38a70485",
      "metadata": {
        "id": "38a70485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702405e0-ab96-4e8f-9ddb-e35a4141b3a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "x.detach().numpy()\n",
        "# numpy는 gradient라는 게 없기 때문"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CqdEZEnAg9p9",
      "metadata": {
        "id": "CqdEZEnAg9p9"
      },
      "source": [
        "세번째로, gpu에 선언된 텐서의 경우 cpu().numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uwST0Z-7g596",
      "metadata": {
        "id": "uwST0Z-7g596"
      },
      "outputs": [],
      "source": [
        "# tensor는 gpu, cpu 전부에서 연산\n",
        "x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True).cuda()\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2wax3zVOhMkf",
      "metadata": {
        "id": "2wax3zVOhMkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ae9f51-ff76-4760-f634-e3de9bf19620"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "# numpy는 cpu에서 연산 이루어짐\n",
        "x.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61fa582a",
      "metadata": {
        "id": "61fa582a"
      },
      "source": [
        "#### 편미분계수 계산 시 상수 텐서와 변수 텐서"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364ca3a4",
      "metadata": {
        "id": "364ca3a4"
      },
      "source": [
        "앞서 살펴본 머신러닝 모델에 대해 경사하강법을 진행하는 경우를 생각해보자.\n",
        "\n",
        "머신러닝 모델을 다음과 같이 정의할 때\n",
        "\\begin{equation}\n",
        "\\mathscr{L}\\big(w_1, ..., w_M ; (x_n, y_n)_{n=0}^{N-1}\\big)\n",
        "\\end{equation}\n",
        "\n",
        "경사하강법을 수행하기 위해 우리는 $\\frac{d\\mathscr{L}}{dw_i}$를 각각의 $w_i$에 대해 계산해야 한다. 그러나, $\\frac{d\\mathscr{L}}{dx_i}$는 필요하지 않다. 특히, 입력 데이터셋이 크고 복잡해질수록, 필요없는 수많은 편미분계수를 일일이 계산하는 것은 쓸데없이 많은 비용이 드는 일이다.\n",
        "\n",
        "위에서 배운대로라면, PyTorch 텐서의 .backward() 메서드는 $\\mathscr{L}$를 이루는 모든 변수 텐서들에 대해 편미분계수를 계산한다. 따라서, 우리는 편미분계수 계산이 필요없는 데이터들을 변수 텐서가 아니라 상수 텐서로 표현함으로써 자동으로 .backward() 계산에서 배제되도록 할 것이다. 상수 텐서로 취급할 수 있는 방법을 알아보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "667de722",
      "metadata": {
        "id": "667de722"
      },
      "source": [
        "PyTorch의 텐서 객체를 생성할 때 requires_grad=False를 사용하여 상수 텐서를 생성할 수 있다. requires_grad=False로 설정된 텐서는 그래디언트 계산에 포함되지 않는다. 기본값이 requires_grad=False이므로, 특별히 지정하지 않아도 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28053219",
      "metadata": {
        "id": "28053219"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(1.)\n",
        "y = tc.tensor(2., requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c2bac7",
      "metadata": {
        "id": "29c2bac7"
      },
      "outputs": [],
      "source": [
        "F = x * y\n",
        "print(F)\n",
        "F.backward()\n",
        "print(F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba47cc3",
      "metadata": {
        "id": "0ba47cc3"
      },
      "outputs": [],
      "source": [
        "F.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb9cb00",
      "metadata": {
        "id": "6fb9cb00"
      },
      "outputs": [],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9355969c",
      "metadata": {
        "id": "9355969c"
      },
      "outputs": [],
      "source": [
        "y.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47018679",
      "metadata": {
        "id": "47018679"
      },
      "source": [
        "추가적으로, 상수 텐서만으로 정의된 텐서의 경우에는 어떤 연산을 적용하더라도 상수 텐서가 생성된다. 따라서, 이렇게 얻은 상수 텐서에 대해서는 .backward() 메서드는 에러를 발생시킨다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be9f9c8",
      "metadata": {
        "id": "9be9f9c8"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(1.)\n",
        "y = tc.tensor(2.)\n",
        "F = x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6005a5",
      "metadata": {
        "id": "ae6005a5"
      },
      "outputs": [],
      "source": [
        "F.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2b85dc5",
      "metadata": {
        "id": "d2b85dc5"
      },
      "outputs": [],
      "source": [
        "F.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b10bbdab",
      "metadata": {
        "id": "b10bbdab"
      },
      "source": [
        "### Step 3. 다차원 텐서의 자동미분 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5989cb5b",
      "metadata": {
        "id": "5989cb5b"
      },
      "source": [
        "#### 다차원 텐서에 대해 정의된 함수에서의 자동미분"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ac6652",
      "metadata": {
        "id": "95ac6652"
      },
      "source": [
        "지금까지는 하나의 스칼라 변수로 이루어진 0차원 텐서에 대해 정의된, 간단한 함수에 대해서만 자동미분을 실행해보았다. 그런데 텐서 객체는 다차원의 배열을 나타낼 수 있다. 따라서 다차원 텐서에 대해 정의된 함수에서 자동미분이 실행되는 방법을 알면 계산을 편리하게 할 수 있다.\n",
        "\n",
        "다차원 텐서와 관련된 .grad 속성을 어떻게 해석해야 할까? 한마디로 표현하면, 텐서의 각 원소를 스칼라 값 변수로 해석하면 된다. 즉, 다차원 텐서를 스칼라 변수들의 집합으로 보면 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c0e308",
      "metadata": {
        "id": "88c0e308"
      },
      "source": [
        "이렇게만 말해서는 이해가 잘 가지 않을 것이다. 다음과 같은 계산을 통해 자세히 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c211a0be",
      "metadata": {
        "id": "c211a0be"
      },
      "outputs": [],
      "source": [
        "tensor = tc.tensor([2.0, 4.0, 8.0], requires_grad=True)\n",
        "arr = tc.tensor([-1.0, 2.0, 0], requires_grad=True)\n",
        "F = (arr * tensor ** 2).sum()\n",
        "F.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a0d070",
      "metadata": {
        "id": "b9a0d070"
      },
      "source": [
        "위의 코드에서 정의된 함수 F를 풀어서 쓰면 $F = -1\\:(x_0)^2 + 2\\:(x_1)^2 + 0\\:(x_2)^2$이다. 그리고 다차원 텐서의 각 원소를 스칼라 값 변수로 해석한다는 것은, $\\mathrm{tensor} = [x_0, x_1, x_2]$로 보겠다는 뜻이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afbb87af",
      "metadata": {
        "id": "afbb87af"
      },
      "source": [
        "이때, tensor.grad에는 어떤 값이 저장되어야 타당할까? tensor의 각 스칼라 변수들로 편미분한 값들을 tensor와 같은 shape의 배열로 저장하면 좋을 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc1254d",
      "metadata": {
        "id": "1fc1254d"
      },
      "source": [
        "\\begin{align}\n",
        "{\\nabla}F &= \\big[\\frac{\\partial F}{\\partial x_0},\\frac{\\partial F}{\\partial x_1},\\frac{\\partial F}{\\partial x_2}\\big]\\\\\n",
        "&= \\big[-2x_0,\\:4x_1,\\:0x_2\\big]\\\\\n",
        "{\\nabla}F\\big|_{x_0=2, x_1=4, x_2=8} &= \\big[-4,\\:16,\\:0\\big]\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd9e4e53",
      "metadata": {
        "id": "cd9e4e53"
      },
      "source": [
        "실제로 tensor.grad 는 tensor에 저장된 특정 값에서의 ${\\nabla}F$ 를 저장한다. 다음 코드를 실행하여 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff494ccb",
      "metadata": {
        "id": "ff494ccb"
      },
      "outputs": [],
      "source": [
        "tensor.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6637697f",
      "metadata": {
        "id": "6637697f"
      },
      "source": [
        "일반화하여 표현하면 다음과 같다. tensor의 각 원소는 스칼라 값 변수로 해석할 수 있고, tensor.grad에서 대응되는 위치의 요소는 해당 변수에 대한 미분계수이다.\n",
        "\n",
        "$\\text{tensor}[x_0, \\dots, x_{(N-1)}] \\rightarrow \\text{tensor.grad}[x_0, \\dots, x_{(N-1)}] = {\\nabla}F = \\big[\\frac{\\partial F}{\\partial x_0},\\dots,\\frac{\\partial F}{\\partial x_{(N-1)}}\\big]$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b333799",
      "metadata": {
        "id": "9b333799"
      },
      "source": [
        "#### 벡터화된 자동미분"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4eca391",
      "metadata": {
        "id": "c4eca391"
      },
      "source": [
        "방금 다차원 텐서에 의해 정의된 스칼라 함수에 대한 자동미분에 대해 배웠다. 이번에는 스칼라 함수가 아닌, 벡터 함수에 대해 자동미분을 실행할 때는 어떻게 실행되는지 알아보자.\n",
        "\n",
        ".backward() 메서드를 호출한 최종 함수가 스칼라가 아니라 벡터 함수라면, PyTorch는 최종 함수를 스칼라로 다 합친 후에 역전파를 진행해야한다.\n",
        "\n",
        "이렇게 합친 $\\sum F$는 스칼라이기 때문에 $\\frac{\\partial (\\sum F)}{\\partial x_{i}}$ 또한 스칼라이다. 따라서 위에서 살펴본 바와 같이 tensor와 tensor.grad는 항상 같은 shape을 갖는다.\n",
        "\n",
        "이렇게만 말해서는 이해가 가지 않으니, 다음과 같은 계산을 통해 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a7cb94",
      "metadata": {
        "id": "43a7cb94"
      },
      "outputs": [],
      "source": [
        "tensor = tc.linspace(-5, 5, 20, requires_grad=True)\n",
        "F = tensor ** 2  # shape-(20)인 텐서\n",
        "F_sum = F.sum()\n",
        "F_sum.backward()\n",
        "#F.backward()\n",
        "tensor.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4fce29",
      "metadata": {
        "id": "6d4fce29"
      },
      "source": [
        "위의 코드에서 정의된 함수 F는 $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$이다. 그리고 PyTorch에서 F_sum.backward()를 실행할 때 이를 스칼라로 다 합친다는 것은, $\\sum {F} = x_0 ^2 + \\dots + x^2_{99}$로 합친 후 이에 대해 .backward()를 실행하겠다는 뜻이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3bc6ee",
      "metadata": {
        "id": "2f3bc6ee"
      },
      "source": [
        "그런데 여기서 의문이 생긴다. 다변수 벡터함수 $F$의 편미분 계수들을 구하기 위해서는 야코비 행렬을 구하는 게 합당해 보인다. 그런데 $\\sum F$에 대해 .backward()를 실행시키는 것은 매우 다른 결과를 불러온다.\n",
        "\n",
        "각 성분함수에 대한 편미분 계수들을 일일이 구하지 못하고, 대신 성분함수들의 합에 대한 편미분 계수 $\\frac{\\partial (F_0+F_1+ \\cdots + F_{N-1})}{\\partial x_i}$ 만을 구하게 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f872b3",
      "metadata": {
        "id": "85f872b3"
      },
      "source": [
        "왜 PyTorch에서는 자동미분 기능을 이렇게 구현한 것일까? 만약 다변수 벡터함수 의 각 성분함수들이 각각 독립인 입력 변수에 대해 정의되었다면, 즉 독립인 $x_0, x_1,\\cdots, x_{(N-1)}$ 에 대해 $F=[F_0(x_0), F_1(x_1), \\cdots, F_{N-1}(x_{(N-1)})]$ 로 정의되었다면 $\\sum F$에 대해 .backward()를 실행시키는 것은 의미있는 행위가 된다. 유효한 모든 편미분 계수를 $\\big[\\frac{\\partial F_{0}}{\\partial x_0},\\dots,\\frac{\\partial F_{N-1}}{\\partial x_{(N-1)}}\\big]$ 와 같이 구할 수 있게 되기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67aadde5",
      "metadata": {
        "id": "67aadde5"
      },
      "source": [
        "다시 위의 예시로 돌아가보자.  $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$에 대해 .backward()를 실행시킨 것은  $\\sum{F} = x_0 ^2 + \\dots + x^2_{99}$에 대해 .backward()를 실행시킨 것과 같다. 그리고 이후에 입력 tensor $\\rm\\textbf{x} = \\big[ x_0, x_1,\\cdots, x_{(N-1)}\\big]$ 에 대한 tensor.grad를 구하면 입력 tensor $\\rm\\textbf{x}$와 shape이 동일한 ${\\nabla}(\\Sigma{{F}}) = \\big[2x_0,\\ \\dots, \\; 2x_{99} \\big]$ 가 구해진다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d7fc45",
      "metadata": {
        "id": "94d7fc45"
      },
      "source": [
        "이 계산은 결국, 100개의 독립적인 값들에 대해 함수 $f(x) = x ^ 2$ 의 편미분계수 값 ($\\frac{\\mathrm{d}f}{\\mathrm{d}x} = 2x$)을 한번에 계산한 것과 같았다. 따라서, PyTorch를 이용하여 독립적인 값들에 대한 성분함수로 이루어진 다변수 벡터 함수의 미분을 구하는 기능은, 여러 개의 독립적인 데이터를 하나의 텐서로 묶어서 동일한 계산을 한 번에 수행할 때 큰 이점이 있다. 신경망에 대해 배우고 본격적인 딥러닝에 대해 실습할 때 도움이 될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b44d37d0",
      "metadata": {
        "id": "b44d37d0"
      },
      "source": [
        "### 문제: 도함수의 그래프 그리기\n",
        "\n",
        ".backward() 메서드를 이용하면 특정 점에서의 그래디언트만 구할 수 있고, 도함수의 식과 그래프는 알 수 없다. 그런데, 벡터화된 자동미분을 이용하면 여러 점에서의 편미분계수 값을 한번에 구할 수 있으므로, matplotlib을 통해 그래프를 찍을 수 있게 된다.\n",
        "\n",
        "1. 벡터화된 자동미분을 수행하는 다음의 함수를 완성해보자. matplotlib에 관한 실습1의 내용을 잘 떠올리면서 작성해보자. (주의: matplotlib에 데이터를 전달할 때는 torch의 텐서가 아닌, 널리 알려진 라이브러리인 NumPy의 배열을 사용하는 것이 좋습니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$의 그래프와 그 도함수를 torch를 이용해서 그려보자."
      ],
      "metadata": {
        "id": "n-UzYgKBZkV9"
      },
      "id": "n-UzYgKBZkV9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b190cf",
      "metadata": {
        "id": "63b190cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae313aa-0a48-43e7-be6e-affb228fde23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0000,  0.0020,  0.0040,  ..., -0.0273, -0.0273, -0.0273],\n",
              "        grad_fn=<MulBackward0>),\n",
              " tensor([2.0000, 1.9987, 1.9973,  ..., 0.0021, 0.0022, 0.0024]))"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "x = tc.linspace(0, 10, 10000, requires_grad=True)\n",
        "y = tc.sin(2 * x) * tc.cos(x) * tc.exp(-x / 3)\n",
        "y_sum = y.sum()\n",
        "y_sum.backward()\n",
        "y, x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a956957d",
      "metadata": {
        "id": "a956957d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_func_and_deriv(x, func):\n",
        "    \"\"\"\n",
        "    함수 func(x)와 도함수 dfunc/dx를 같은 축(axis) 상에 그리는 함수\n",
        "\n",
        "    매개변수 (Parameters)\n",
        "    ----------\n",
        "    x : PyTorch.Tensor, shape-(N,)\n",
        "        함수 func(x)와 도함수 dfunc/dx를 그리는 x의 정의역\n",
        "\n",
        "    func: Callable[[Tensor], Tensor]\n",
        "        x에 대한 일변수 함수\n",
        "\n",
        "    반환 값 (Returns)\n",
        "    -------\n",
        "    Tuple[Figure, Axis]\n",
        "        matplotlib로 그래프를 그리기 위한 fig와 ax\n",
        "    \"\"\"\n",
        "    x = tc.tensor(x, requires_grad=True)\n",
        "    y = func(x)\n",
        "    y.sum().backward()\n",
        "\n",
        "    # 여기에 코드 작성\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(x.detach().numpy(), y.detach().numpy(), c=\"red\")\n",
        "    ax.plot(x.detach().numpy(), x.grad.detach().numpy(), c=\"blue\")\n",
        "    ax.grid(True)\n",
        "\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6565d15f",
      "metadata": {
        "id": "6565d15f"
      },
      "source": [
        "2. 이제 위에서 작성한 함수를 이용하여 구간 $[0, 10]$를 균등하게 10,000개로 나눈 정의역에 대해 함수 $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$와 그 도함수의 그래프를 그려보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72733202",
      "metadata": {
        "id": "72733202"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    # 여기에 코드 작성\n",
        "    return tc.sin(2 * x) * tc.cos(x) * tc.exp(-x / 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5f677e",
      "metadata": {
        "id": "7c5f677e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "5e03e52f-121f-41c0-f087-7b4fb4997c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-a5175a552b13>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = tc.tensor(x, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = tc.linspace(0, 10, 10000)\n",
        "fig, ax = plot_func_and_deriv(x, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a1f72a",
      "metadata": {
        "id": "c0a1f72a"
      },
      "source": [
        "### Step 4. Torch의 자동미분을 이용한 경사하강법"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b0de77",
      "metadata": {
        "id": "72b0de77"
      },
      "source": [
        "#### 경사하강법 코드 수정하기 (1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2062d0",
      "metadata": {
        "id": "6a2062d0"
      },
      "source": [
        "자동미분을 이용하면 경사하강법을 쉽게 구현할 수 있다. 연습을 위해 간단한 일변수 함수에 대해 경사하강법을 수행해볼 것이다. 앞선 예제에서도 다룬적 있는 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n",
        "\n",
        "앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_parabola()를 작성해보았다.\n",
        "\n",
        "```python\n",
        "def descent_down_parabola(w_start, learning_rate, num_steps):\n",
        "    w_values = [w_start]\n",
        "    for _ in range(num_steps):\n",
        "        w_old = w_values[-1]\n",
        "        w_new = w_old - learning_rate * (2 * w_old)\n",
        "        w_values.append(w_new)\n",
        "    return np.array(w_values)\n",
        "```\n",
        "\n",
        "이번에는 도함수를 모르는 $\\mathscr{L}(w)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. $w$의 값을 PyTorch 텐서로 저장한 후, $\\mathscr{L}(w)$를 $w$의 식으로 정의해주어, .backward() 메서드를 사용하여 편미분계수를 구할 수 있다.\n",
        "\n",
        "아래의 경사하강법 공식에 따라 자동미분을 이용한 경사하강법을 프로그래밍으로 구현해보자.\n",
        "\n",
        "\\begin{equation}\n",
        "w_{\\mathrm{new}} = w_{\\mathrm{old}} - \\delta \\frac{\\mathrm{d}\\mathscr{L}}{\\mathrm{d}w}\\big|_{w_{\\mathrm{old}}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2da681a1",
      "metadata": {
        "id": "2da681a1"
      },
      "source": [
        "다음과 같이 $w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "941881f8",
      "metadata": {
        "id": "941881f8"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor([10.0], requires_grad=True)\n",
        "learning_rate = 0.3\n",
        "num_steps = 20 # epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bfcec4",
      "metadata": {
        "id": "64bfcec4"
      },
      "source": [
        "이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n",
        "```\n",
        "Tensor(4.)\n",
        "Tensor(1.6)\n",
        "Tensor(0.64)\n",
        "Tensor(0.256)\n",
        "Tensor(0.1024)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fda26a0",
      "metadata": {
        "id": "7fda26a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725b74a8-8fcb-4838-cdbf-a4f5580d6d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.], requires_grad=True)\n",
            "tensor([1.6000], requires_grad=True)\n",
            "tensor([0.6400], requires_grad=True)\n",
            "tensor([0.2560], requires_grad=True)\n",
            "tensor([0.1024], requires_grad=True)\n",
            "tensor([0.0410], requires_grad=True)\n",
            "tensor([0.0164], requires_grad=True)\n",
            "tensor([0.0066], requires_grad=True)\n",
            "tensor([0.0026], requires_grad=True)\n",
            "tensor([0.0010], requires_grad=True)\n",
            "tensor([0.0004], requires_grad=True)\n",
            "tensor([0.0002], requires_grad=True)\n",
            "tensor([6.7109e-05], requires_grad=True)\n",
            "tensor([2.6844e-05], requires_grad=True)\n",
            "tensor([1.0737e-05], requires_grad=True)\n",
            "tensor([4.2950e-06], requires_grad=True)\n",
            "tensor([1.7180e-06], requires_grad=True)\n",
            "tensor([6.8719e-07], requires_grad=True)\n",
            "tensor([2.7488e-07], requires_grad=True)\n",
            "tensor([1.0995e-07], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for _ in range(num_steps):\n",
        "    ℒ = w ** 2 # w를 0에 최대한 가깝게 만들어줘야함\n",
        "    ℒ.backward()\n",
        "    # 여기에 코드 작성\n",
        "\n",
        "    #  블록 안에서 w를 업데이트. 이는 PyTorch가 이 블록 내의 연산을 추적하지 않도록 한다.\n",
        "    #  pytorch가 계산 그래프를 생성하지 않도록 함 => 불필요한 메모리 사용 억제\n",
        "    with tc.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "    #w의 그래디언트를 초기화. 이를 통해 다음 단계에서 그래디언트가 누적되지 않도록 한다.\n",
        "    w.grad = None\n",
        "\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "604b8e15",
      "metadata": {
        "id": "604b8e15"
      },
      "source": [
        "그런데 코드를 작성할 때, 한가지 생각해볼만한 부분이 있다. 위의 코드를 완성하여 원하는 출력값도 제대로 얻었다면, 아래의 두 코드와 자신의 답변을 비교해보자. 꼭 먼저 코드를 직접 작성해본 후에 답변을 확인하길 바란다.\n",
        "\n",
        "다음의 두 코드는 모두 원하는 출력값을 얻게 해주는 코드이다.\n",
        "첫번째 코드는 다음과 같다.\n",
        "```python\n",
        "w = w - learning_rate * w.grad\n",
        "```\n",
        "두번째 코드는 다음과 같다.\n",
        "```python\n",
        "w.data -= learning_rate * w.grad\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205b2767",
      "metadata": {
        "id": "205b2767"
      },
      "source": [
        "두 코드는 동일한 출력값을 얻게 해줄 뿐 아니라, 사실상 같은 의미라고 느껴진다. 그리고 첫번째 코드가 우리가 알고 있는 공식에 더 가까원 형태이기 때문에 좀 더 직관적이다. 그러나, 두번째 코드는 두가지 이점이 있다.\n",
        "\n",
        "첫째로 컴퓨터 계산 속도를 최적화할 수 있다. 앞서 PyTorch의 텐서는 NumPy 배열의 수학적 연산들을 추적하는 추가 기능을 갖고 있는 객체라는 것을 배웠다. 그러나 이렇게 수학 연산을 추적하는 과정이 w 값을 갱신하는 과정에서는 굳이 필요하지 않다. 따라서 첫번째 코드와 같이 텐서를 사용하면, 불필요한 수학 연산의 추적으로 인해 간접적인 연산 처리 시간인 오버헤드(overhead)만 발생한다. 그러나 두번째 코드에서는 직접 텐서의 데이터를 업데이트함으로써, 불필요한 연산 그래프 추적을 피한다.\n",
        "\n",
        "둘째로 추가적인 메모리 공간을 필요로 하지 않는다. 연산자 '-='는 증강 업데이트(augmented update)를 실행하는 연산자이다. 이는 컴퓨터가 새로운 메모리 공간을 할당하여 배열의 값을 교체하는 대신, 사용하던 메모리 공간을 그대로 다시 덮어쓰는 것을 의미한다. 따라서 기존 메모리 공간을 그대로 사용하므로, 메모리 사용이 최적화된다.\n",
        "\n",
        "조만간 신경망에 대해 배운 후, 어렵고 복잡한 수학적 함수의 파라미터를 조정하게 되면, 수많은 대규모 데이터를 업데이트하게 될 것이다. 이런 상황에서 위의 두가지 이점은 학습의 성능에 큰 차이를 만들 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "606ef82a",
      "metadata": {
        "id": "606ef82a"
      },
      "source": [
        "#### 경사하강법 코드 수정하기 (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf2419b9",
      "metadata": {
        "id": "cf2419b9"
      },
      "source": [
        "이번에는 앞선 예제에서 다룬적 있는 이변수 함수 $\\mathscr{L}(w_1, w_2) = 2w_1^2 + 3w_2^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n",
        "\n",
        "앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_2d_parabola()를 작성해보았다.\n",
        "\n",
        "```python\n",
        "def descent_down_2d_parabola(w_start, learning_rate, num_steps):\n",
        "    xy_values = [w_start]\n",
        "    for _ in range(num_steps):\n",
        "        xy_old = xy_values[-1]\n",
        "        xy_new = xy_old - learning_rate * (np.array([4., 6.]) * xy_old)\n",
        "        xy_values.append(xy_new)\n",
        "    return np.array(xy_values)\n",
        "```\n",
        "\n",
        "이번에는 도함수를 모르는 $\\mathscr{L}(w_1, w_2)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. 다차원 텐서로 정의된 함수의 자동미분을 잘 떠올리면 해결하는 데 도움이 될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0657ae3",
      "metadata": {
        "id": "f0657ae3"
      },
      "source": [
        "다음과 같이 $\\rm\\textbf w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ff9d793",
      "metadata": {
        "id": "8ff9d793"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor([2., 4.], requires_grad=True)\n",
        "learning_rate = 0.1\n",
        "num_steps = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c03fd2c5",
      "metadata": {
        "id": "c03fd2c5"
      },
      "source": [
        "이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w_1=0, w_2=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n",
        "```\n",
        "Tensor([1.2, 1.6])\n",
        "Tensor([0.72, 0.64])\n",
        "Tensor([0.432, 0.256])\n",
        "Tensor([0.2592, 0.1024])\n",
        "Tensor([0.15552, 0.04096])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc9819f",
      "metadata": {
        "id": "6dc9819f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a66116a-cbfa-4ae4-985f-b52f73fcd1d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2000, 1.6000], requires_grad=True)\n",
            "tensor([0.7200, 0.6400], requires_grad=True)\n",
            "tensor([0.4320, 0.2560], requires_grad=True)\n",
            "tensor([0.2592, 0.1024], requires_grad=True)\n",
            "tensor([0.1555, 0.0410], requires_grad=True)\n",
            "tensor([0.0933, 0.0164], requires_grad=True)\n",
            "tensor([0.0560, 0.0066], requires_grad=True)\n",
            "tensor([0.0336, 0.0026], requires_grad=True)\n",
            "tensor([0.0202, 0.0010], requires_grad=True)\n",
            "tensor([0.0121, 0.0004], requires_grad=True)\n",
            "tensor([0.0073, 0.0002], requires_grad=True)\n",
            "tensor([4.3536e-03, 6.7109e-05], requires_grad=True)\n",
            "tensor([2.6121e-03, 2.6844e-05], requires_grad=True)\n",
            "tensor([1.5673e-03, 1.0737e-05], requires_grad=True)\n",
            "tensor([9.4037e-04, 4.2950e-06], requires_grad=True)\n",
            "tensor([5.6422e-04, 1.7180e-06], requires_grad=True)\n",
            "tensor([3.3853e-04, 6.8719e-07], requires_grad=True)\n",
            "tensor([2.0312e-04, 2.7488e-07], requires_grad=True)\n",
            "tensor([1.2187e-04, 1.0995e-07], requires_grad=True)\n",
            "tensor([7.3123e-05, 4.3980e-08], requires_grad=True)\n",
            "tensor([4.3874e-05, 1.7592e-08], requires_grad=True)\n",
            "tensor([2.6324e-05, 7.0369e-09], requires_grad=True)\n",
            "tensor([1.5795e-05, 2.8147e-09], requires_grad=True)\n",
            "tensor([9.4768e-06, 1.1259e-09], requires_grad=True)\n",
            "tensor([5.6861e-06, 4.5036e-10], requires_grad=True)\n",
            "tensor([3.4116e-06, 1.8014e-10], requires_grad=True)\n",
            "tensor([2.0470e-06, 7.2058e-11], requires_grad=True)\n",
            "tensor([1.2282e-06, 2.8823e-11], requires_grad=True)\n",
            "tensor([7.3691e-07, 1.1529e-11], requires_grad=True)\n",
            "tensor([4.4215e-07, 4.6117e-12], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "const = tc.tensor([2.0, 3.0])\n",
        "for _ in range(num_steps):\n",
        "    ℒ = const * w ** 2\n",
        "    ℒ.sum().backward()\n",
        "    # 여기에 코드 작성\n",
        "\n",
        "    # w 업데이트 (메모리 최적화)\n",
        "    with tc.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # w 값 출력\n",
        "    print(w)\n",
        "\n",
        "    # 그래디언트 초기화\n",
        "    w.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f86fbb1",
      "metadata": {
        "id": "8f86fbb1"
      },
      "source": [
        "#### 일반적인 경사하강법 함수 작성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "633555d6",
      "metadata": {
        "id": "633555d6"
      },
      "source": [
        "일변수 함수, 다변수 함수에 대해 경사하강법을 수행해보았으니, 보편적인 상황에 대해 적용할 수 있는 일반적인 경사하강법 함수를 작성하는 것만 남았다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78175514",
      "metadata": {
        "id": "78175514"
      },
      "source": [
        "<문제: 일반적인 경사하강법 함수 작성하기>\n",
        "\n",
        "이 문제의 목표는 어떤 함수가 어떤 텐서로 정의되어 있는지에 상관없이 사용할 수 있는 경사하강법 함수를 작성하는 것이다. 함수 외부에서 텐서와 텐서들로 정의된 함수를 모두 정의한 후, .backward() 메서드까지 실행한다. 함수 내부로는 텐서들만 전달해주어, 함수 내에서는 그 텐서들을 이용하여 경사하강법을 실행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8ac2fb",
      "metadata": {
        "id": "4d8ac2fb"
      },
      "source": [
        "아래 함수의 주석을 잘 보고, 일반적인 경사하강법 함수를 작성해보자. 주석을 보면 이 함수는 단일 텐서를 인자로 입력받을 수도 있지만, 여러개의 텐서로 이루어진 iterable한 객체를 입력받을 수도 있다. 어떻게 코딩해야 할지 막막한 느낌이 든다면, 다음 힌트를 살펴보자.\n",
        "\n",
        "> HINT\n",
        "> 1. 여러 개의 텐서로 이루어진 iterable한 자료형이 들어올 수 있으므로, for문을 이용하여 텐서를 하나씩 꺼내며 경사하강하는 코드를 작성해야한다.\n",
        "> 2. 단일 텐서가 들어오면 for문을 이용할 수 없으므로, 단일 텐서를 단일 텐서가 들어있는 리스트로 바꾸어주는 과정이 있어야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db9666b8",
      "metadata": {
        "id": "db9666b8"
      },
      "outputs": [],
      "source": [
        "def gradient_step(tensors, learning_rate):\n",
        "    \"\"\"\n",
        "    경사하강법의 공식에 따라 gradient-step을 실행.\n",
        "\n",
        "    매개변수 (Parameters)\n",
        "    ----------\n",
        "    tensors : Union[Tensor, Iterable[Tensors]]\n",
        "        단일 텐서, 혹은 텐서로 이루어진 iterable(리스트, 튜플 등) 모두 가능\n",
        "        만약 특정 tensor에 대한 `tensor.grad`가 `None`인 경우, 업데이트를 건너 뜀\n",
        "\n",
        "    learning_rate : float\n",
        "        매 gradient-step에서의 학습률. 양수\n",
        "\n",
        "    참고\n",
        "    -----\n",
        "    함수에서 진행되는 모든 gradient-steps는 tensor 내에서 바로 반영되므로, 반환 값 없음\n",
        "    \"\"\"\n",
        "    # isinstance 함수를 이용하여 입력된 tensors가 단일 텐서인지, iterable인지 판단한다\n",
        "    # tensor의 크기에 관계없이 항상 작동하게\n",
        "\n",
        "    if isinstance(tensors, tc.Tensor):\n",
        "        # Only one tensor was provided. Pack\n",
        "        # it into a list so it can be accessed via\n",
        "        # iteration\n",
        "        tensors = [tensors]\n",
        "        # 단일텐서이면 한 번 감싸주어야 반복문 실행 가능\n",
        "\n",
        "    # for 문을 이용하여 tensors의 tensor를 하나씩 꺼내며 경사하강을 진행\n",
        "    for t in tensors:\n",
        "      if t.grad is not None:\n",
        "        t.data -= learning_rate * t.grad\n",
        "        t.grad.zero_() # 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63edb99a",
      "metadata": {
        "id": "63edb99a"
      },
      "source": [
        "앞서 수행했던 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 다시 한번 실행해봄으로써 보편적인 경사하강법 함수가 우리가 원하는대로 동작하는지 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf280d6",
      "metadata": {
        "id": "fbf280d6"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor(10.0, requires_grad=True)\n",
        "learning_rate = 0.3\n",
        "num_steps = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9abee228",
      "metadata": {
        "id": "9abee228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d436ee-d3d2-42bd-8a82-ac185a06b300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4., requires_grad=True)\n",
            "tensor(1.6000, requires_grad=True)\n",
            "tensor(0.6400, requires_grad=True)\n",
            "tensor(0.2560, requires_grad=True)\n",
            "tensor(0.1024, requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for _ in range(num_steps):\n",
        "    ℒ = w ** 2\n",
        "    ℒ.backward()\n",
        "    gradient_step(w, learning_rate = learning_rate)\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99313c60",
      "metadata": {
        "id": "99313c60"
      },
      "source": [
        "### 배운 내용 되돌아보기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cecca3d9",
      "metadata": {
        "id": "cecca3d9"
      },
      "source": [
        "이번 실습에서는 자동미분을 도와주는 PyTorch 라이브러리의 사용법을 배우고 익혔다. PyTorch는 앞으로의 거의 모든 실습에서 사용되는 중요한 라이브러리이다.\n",
        "\n",
        "- Tensor를 생성하는 여러 가지 함수들을 사용해보았다. 원소를 직접 적어줄 수도 있고, 리스트, 튜플, NumPy의 ndarray 등으로부터 Tensor를 생성할 수도 있었다.\n",
        "\n",
        "- 기존에 생성된 Tensor의 행과 열을 자유자재로 바꾸거나 일부 행이나 열만 슬라이싱 해보았다.\n",
        "\n",
        "- PyTorch에서 제공하는 다양한 수학 연산 함수들을 사용해보았다. 그 과정에서 NumPy의 함수들과의 유사성을 확인하였다.\n",
        "\n",
        "- 선형대수 연산을 돕는 함수인 matmul()과 einsum()을 사용해보았다.\n",
        "\n",
        "- PyTorch에 딥러닝을 위한 특수 함수들이 다양하게 존재함을 알게 되었으나, 사용해보지는 않았다.\n",
        "\n",
        "- PyTorch 텐서 객체의 .backward() 메서드를 사용하여 자동미분을 실행하고, 텐서의 .grad 속성을 이용하여 편미분 계수를 구해보았다.\n",
        "\n",
        "- 경사하강을 반복하며 최적의 모델을 찾아갈 때, 경사하강이 1회 종료될 때마다 기존의 편미분 계수를 폐기해주어야 함을 알게 되었다. 이를 위해 .grad 속성을 폐기하는 방법을 직접 사용해보았다.\n",
        "\n",
        "- PyTorch 텐서와 NumPy의 배열 사이의 관계를 알게 되었다.\n",
        "\n",
        "- 불필요한 편미분 계수를 계산하는 것을 방지하기 위해, 텐서를 상수 취급하는 방법을 도입해야 함을 알게 되었다. 그리고 텐서를 상수 취급하기 위한 방법을 사용해보았다.\n",
        "\n",
        "- 다차원 텐서에 대해 정의된 함수 (다변수 함수)에서 자동미분을 실행하면 다차원 텐서의 각 원소가 스칼라 값 변수로 해석되어 자동미분이 이루어짐을 알게 되었다. 또한 다차원 텐서의 .grad 속성에 함수의 그래디언트 값이 저장됨을 확인하였다.\n",
        "\n",
        "- 다변수 벡터 함수에 대해 자동미분을 실행하면 모든 성분함수를 합한 것에 대해 자동미분이 이루어짐을 알게 되었다. 또한 이런 규칙이 어떤 유용함을 가지는지 확인하였다.\n",
        "\n",
        "- PyTorch의 자동미분을 이용하여 경사하강법 함수를 새롭게 구현해보았다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649f5f3b",
      "metadata": {
        "id": "649f5f3b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "61fa582a",
        "b10bbdab"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}